STRATEGI TUNING DETAIL
A. FEATURE ENGINEERING
python
# 1. Tambahkan Technical Indicators yang lebih robust
def enhanced_features(df):
    # Momentum Indicators
    df['rsi'] = ta.RSI(df['close'])
    df['stoch_k'] = ta.STOCH(df['high'], df['low'], df['close']).iloc[:,0]
    df['stoch_d'] = ta.STOCH(df['high'], df['low'], df['close']).iloc[:,1]
    
    # Trend Indicators
    df['adx'] = ta.ADX(df['high'], df['low'], df['close'])
    df['cci'] = ta.CCI(df['high'], df['low'], df['close'])
    
    # Volatility Features
    df['atr'] = ta.ATR(df['high'], df['low'], df['close'])
    df['bb_width'] = (ta.BBANDS(df['close']).iloc[:,0] - ta.BBANDS(df['close']).iloc[:,2]) / df['close']
    
    # Volume-based Features
    df['volume_sma'] = df['volume'].rolling(20).mean()
    df['volume_ratio'] = df['volume'] / df['volume_sma']
    df['obv'] = ta.OBV(df['close'], df['volume'])
    
    # Price Action Features
    df['price_range'] = (df['high'] - df['low']) / df['close']
    df['body_size'] = abs(df['close'] - df['open']) / df['close']
    
    return df
B. DATA QUALITY IMPROVEMENT
python
# 1. Minimum Data Threshold
MIN_DATA_POINTS = 500  # Increase from current

# 2. Data Validation
def validate_training_data(df, symbol):
    if len(df) < MIN_DATA_POINTS:
        print(f"⚠️ {symbol}: Insufficient data ({len(df)} bars)")
        return False
    
    # Check for NaN values
    if df.isnull().sum().sum() > len(df) * 0.1:
        print(f"⚠️ {symbol}: Too many missing values")
        return False
    
    # Check price validity
    if (df['close'] <= 0).any():
        print(f"⚠️ {symbol}: Invalid price data")
        return False
        
    return True

# 3. Outlier Handling
def remove_outliers(df, columns, threshold=3):
    for col in columns:
        z_scores = np.abs(stats.zscore(df[col]))
        df = df[z_scores < threshold]
    return df
C. MODEL ARCHITECTURE ENHANCEMENT
python
# 1. Hyperparameter Tuning Strategy
def get_optimized_hyperparameters(symbol, data_size):
    base_params = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2']
    }
    
    # Adaptive tuning based on data size
    if data_size < 300:
        base_params['n_estimators'] = [50, 100]
        base_params['max_depth'] = [5, 10]
    
    return base_params

# 2. Multi-Model Ensemble
models_to_test = {
    'random_forest': RandomForestClassifier(),
    'xgboost': XGBClassifier(),
    'lightgbm': LGBMClassifier(),
    'gradient_boosting': GradientBoostingClassifier()
}
D. ADVANCED VALIDATION STRATEGY
python
# 1. Robust Cross-Validation
def time_series_cv_score(model, X, y, cv_splits=5):
    tscv = TimeSeriesSplit(n_splits=cv_splits)
    scores = []
    
    for train_idx, test_idx in tscv.split(X):
        # Ensure time order
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        
        model.fit(X_train, y_train)
        pred = model.predict(X_test)
        scores.append(accuracy_score(y_test, pred))
    
    return np.mean(scores), np.std(scores)

# 2. Confidence-based Filtering
def confidence_based_prediction(model, X, confidence_threshold=0.6):
    probabilities = model.predict_proba(X)
    max_probs = np.max(probabilities, axis=1)
    
    # Only return predictions with high confidence
    confident_mask = max_probs >= confidence_threshold
    predictions = model.predict(X)
    
    return predictions[confident_mask], max_probs[confident_mask]
E. PERFORMANCE MONITORING
python
# 1. Model Quality Metrics
def evaluate_model_quality(accuracy, data_size, feature_count):
    """Composite score for model reliability"""
    size_score = min(1.0, data_size / 1000)  # Normalize data size
    feature_score = min(1.0, feature_count / 20)  # Reasonable feature count
    
    quality_score = (
        accuracy * 0.6 +          # Accuracy weight
        size_score * 0.3 +        # Data quality weight  
        feature_score * 0.1       # Feature richness weight
    )
    
    return quality_score

# 2. Adaptive Training Selection
def adaptive_training_selection(symbols_data, min_quality=0.55):
    """Only train models expected to perform well"""
    selected = []
    
    for symbol, data in symbols_data.items():
        # Pre-screen data quality
        if not validate_training_data(data, symbol):
            continue
            
        # Estimate potential accuracy
        expected_accuracy = estimate_potential_accuracy(data)
        
        if expected_accuracy >= min_quality:
            selected.append(symbol)
    
    return selected